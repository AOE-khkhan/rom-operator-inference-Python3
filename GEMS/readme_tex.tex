% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{changepage}

\newenvironment{myind}{\begin{adjustwidth}{2cm}{}}{\end{adjustwidth}}

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
%\geometry{a4paper} % or letterpaper (US) or a5paper or....
\geometry{margin = .75in}
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES


\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
%\usepackage{sectsty}
%\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)
\usepackage{titlesec}

\renewcommand{\thesection}{\textbf{Section} \arabic{section}}
\renewcommand{\thesubsection}{Section \arabic{section}.\arabic{subsection}}



%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!
\usepackage{xcolor}
\definecolor{light-gray}{gray}{0.95}
\newcommand{\code}[1]{\colorbox{light-gray}{\texttt{#1}}}
%%% END Article customizations
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bH}{\mathbf{H}}
%%% The "real" document content comes below...

\title{Readme for operator inference on GEMS data}
\author{Renee Swischuk}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle
\section{Preprocessing, lifting and scaling GEMS data}
\hrulefill\\
\textbf{Scripts}: \code{tec2h5.py}\\
\textbf{Dependencies}: \code{chemistry\_conversions.py, scaling\_tools.py}

\noindent\hrulefill\\
The script \textit{tec2h5.py} does the following
\begin{itemize}
\item[--] Read in GEMS .dat files from the folder \textit{OriginalGEMS}
\item[--] Convert mass fractions to molar concentrations 
\item[--] Replace temperature with specific volume
\item[--] Stack the variables vertically and save the numVars*numElements $\times$ numSnaps dataset as \textit{data\_unscaled.h5} in the folder \textit{OpInfdata}
\item[--] Scale to the range [-1,1]
\item[--] Save the scaled data as \textit{data\_minmax.h5} in the folder \textit{OpInfdata}
\end{itemize}

\noindent To access either of the datasets, run the following commands:\\
\code{import h5py}\\
\code{data\_file = h5py.File('data\_minmax.h5','r')}\\
\code{dataset = data\_file['data'][:,:]}
\newpage
\section{Computing POD basis, reducing data and computing xdot}
\hrulefill\\
\textbf{Scripts}: \code{projection\_helpers.py}\\
\textbf{Dependencies}: 

\noindent\hrulefill\\

\noindent Run the script \code{projection\_helpers.py}.\\

\noindent \textbf{1)} You will be asked for the number of snapshots you want to compute the svd of/reduce. \\
Type this number in and click enter. \\

\noindent \textbf{2)} You will be asked if you want to compute the SVD. \\
\noindent Type True and click enter if you want to compute the SVD of the data (the data will be read from the file \textit{OpInfdata/data\_minmax.h5}). \\
\indent \textbf{2a)} You will then be prompted for the truncation value for the randomized SVD algorithm.\\
\indent Type this number in and click enter.\\
The SVD will be saved to the file \textit{OpInfdata/svd\_nt\%d.h5} where \%d = number of training snapshots you entered. There will be two datasets in the h5 file, one for the singular vectors, called `U', and one for the singular values, called `S'\\

\noindent Type False and click enter if you already have the SVD stored in \textit{OpInfdata/svd\_nt\%d.h5} with datasets `U' and `S' for singular vectors and values. 
\\

\noindent After the prompts, the script \code{projection\_helpers.py} will do the following:
\begin{itemize}
\item[--] Load the scaled data from \textit{OpInfdata/data\_minmax.h5}) 
\item[--] (optionally) Compute the SVD of the data and save 
\item[--] Compute the time derivative of the scaled data
\item[--] Project data and time derivative onto POD basis of size $r$ -- multiple values for $r$ can be given and must be input directly in the code at line 263 in the \code{main()} function.
\item[--] Save the projected data and xdot into files \\ \textit{OpInfdata/reducedData/data\_reduced\_minmax\_nt\%d/data\_reduced\_\%d.h5} \%(nt,r) and \\ \textit{OpInfdata/reducedData/xdot\_reduced\_minmax\_nt\%d/xdot\_reduced\_\%d.h5} \%(nt,r)\\

The reduced datasets are read with the following commands:\\
\code{df= h5py.File(`OpInfdata/reducedData/data\_reduced\_minmax\_nt5000/data\_reduced\_8.h5',`r')}\\
\code{data = df[`data'][:,:]} -- numVars*numElements $\times$ r array\\
\code{xf = h5py.File(`OpInfdata/reducedData/xdot\_reduced\_minmax\_nt5000/xdot\_reduced\_8.h5',`r')}\\
\code{xdot = xf[`xdot'][:,:]} -- numVars*numElements $\times$ r array\\

The SVD data is read with the following commands:\\
\code{svd\_file = h5py.File(`svd\_nt5000.h5',`r')}\\
\code{singular\_values = svd\_file[`S']}\\
\code{singular\_vectors = svd\_file[`U']}

\end{itemize}

\section{Operator inference package}
\hrulefill\\
\textbf{Scripts}: \code{opinf\_demo.py}\\
\textbf{Dependencies}: operator\_inference package -- see https://test.pypi.org/project/operator-inference/

\noindent\hrulefill\\

\noindent The first step is to download the operator inference module from pip. In the command prompt, type\\
\code{pip3 install -i https://test.pypi.org/simple/ operator-inference} \\
\textit{This is temporary}\\






\noindent The \code{operator\_inference} package contains a \code{model} class, with functions defined in \ref{sec:modelclassfunctions}, and two helper scripts called \code{opinf\_helper.py} and \code{integration\_helpers.py}, with functions defined in \ref{sec:opinfhelperfunctions} and \ref{sec:integrationhelpersfunctions}, respectively. \\
\subsection{Quick Start}
\code{from operator\_inference import OpInf}\\

\noindent \#define the model \\
\code{mymodel = OpInf.model('Lc',False) \# a linear quadratic with no input}\\


\noindent \#fit the model\\
\code{mymodel.fit(r,k,xdot,xhat)}\\

\noindent \#simulate the model for train and test time steps\\
\code{xr,break\_point = mymodel.predict(xhat[:,0], n\_t, dt)}\\

\noindent \#reconstruct the predictions\\
\code{xr\_rec = U[:,:r]@xr}

\subsection{ Model class}

The following commands will initialize an operator inference model. \\
\indent \code{from operator\_inference import OpInf}\\
\indent \code{my\_model = OpInf.model(degree, input)}\\

\noindent where \code{degree} is a string denoting the degree of the model with the following options
\begin{itemize}
\item[] `L'  -- a linear model, $\dot{\bx} = \bA \bx$\\
\item[] `Lc' -- a linear model with a constant, $\dot{\bx} = \bA \bx + \bc$\\
\item[] `LQ' -- a linear and quadratic model, $\dot{\bx} = \bA \bx + \bF \bx^2$\\
\item[] `LQc' -- a linear and quadratic model with a constant, $\dot{\bx} = \bA \bx + \bF \bx^2 + \bc$\\
\item[] `Q' -- a quadratic model, $\dot{\bx} = \bF \bx^2$\\
\item[] `Qc' -- a quadratic model with a constant, $\dot{\bx} = \bF \bx^2 + \bc$
\end{itemize}
The \code{input} argument is a boolean (True or False) denoting whether or not there is an additive input term of the form $+\mathbf{B} \mathbf{U}$.\\

\noindent The script, \code{opinf\_demo.py} demonstrates the use of the operator inference model on data generated from the heat equation. See \cite{mythesis} for the problem setup. 
 
\subsubsection{Model class functions}
\label{sec:modelclassfunctions}
Functions can be called as \code{mymodel.function\_name()}
\begin{enumerate}
\item{\code{fit(r,reg,xdot,xhat,u=None)}}\\
Find the operators of the reduced-order model that fit the data \\
\textbf{Parameters}:
	\begin{itemize}
		\item[] r -- (integer) POD basis size
		\item[]reg -- (float) L$_2$ regularization parameter. For no regularization, set to 0.
		\item[] xdot -- ($r \times n_t$ array) the reduced time derivative data
		\item[]xhat-- ($r \times n_t$ array) the reduced snapshot data
		\item[]u -- ($p \times n_t$ array, optional) the input, if \code{model.input = True}
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] None
\end{itemize}


\item \code{predict(init, n\_timesteps, dt, u = None)}\\
Simulate the learned model with a Runge Kutta scheme\\
\textbf{Parameters}:
	\begin{itemize}
		\item[] init -- ($r \times 1$) intial reduced state
		\item[]n\_timesteps -- (int) number of time steps to simulate
		\item[]dt-- (float) the time step size
		\item[]u -- ($p \times$ n\_timesteps array) the input at each simulation time step 
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] projected\_state -- ($r \times$ n\_timesteps array) the simulated, reduced states
\item[] i -- (int) the time step that the simulation ended on ($ i < $n\_timesteps only if NaNs occur in simulation)
\end{itemize}

\item{\code{get\_residual()}}\\
Get the residuals of the least squares problem\\
\textbf{Parameters}:
	\begin{itemize}
		\item[] None
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] residual -- (float) residual of data fit, $\Vert \mathbf{D}\mathbf{O}^T -\dot{ \mathbf{X}}^T \Vert_2^2$
\item[] solution -- (float) residual of the solution, $\Vert \mathbf{O}^T \Vert_2^2$
\end{itemize}

\item{ \code{get\_operators()}}\\
Get the learned operators\\
\textbf{Parameters}:
	\begin{itemize}
		\item[] None
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] ops -- (tuple) containing each operator (as an array) as defined by \code{degree} of the model
\end{itemize}

\end{enumerate}
\newpage
\subsection{\code{opinf\_helper.py} }
Import the opinf helper script as\\
 \indent \code{from operator\_inference import opinf\_helper}. \\


\subsubsection{\code{opinf\_helper.py} functions}
\label{sec:opinfhelperfunctions}
The following functions are supported and called as \code{opinf\_helper.function\_name()}. 
\begin{enumerate}

\item{\code{normal\_equations(D,r,k,num)}}\\
Solves the normal equations corresponding to the regularized least squares problem \\$\displaystyle\min_{\mathbf{o}_i} \Vert \mathbf{D}\mathbf{o}_i - \mathbf{r}_i\Vert_2^2 + k\Vert \mathbf{P}\mathbf{o}_i\Vert_2^2$\\
\textbf{Parameters}:
	\begin{itemize}
	\item[] D -- (nd array) data matrix
	\item[] r -- (nd array) reduced time derivative data 
	\item[] k -- (float) regularization parameter 
	\item[] num -- (int) number of ls problem we are solving [1..r]
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] $\mathbf{o}_i$ -- (nd array) the solution to the least squares problem
\end{itemize}

\item{\code{get\_x\_sq(X)}}\\
Compute squared snapshot data as in \cite{ben}. \\
\textbf{Parameters}:
	\begin{itemize}
	\item[] X -- ($n_t \times r$ array) reduced snapshot data (transposed)
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] X$^2$ -- ($n_t \times \frac{r(r+1)}{2}$ array) reduced snapshot data squared without redundant terms.
\end{itemize}

\item{\code{F2H(F)}}\\
Convert quadratic operator $\mathbf{F}$ to symmetric quadratic operator $\mathbf{H}$ for simulating the learned system.\\
\textbf{Parameters}:
	\begin{itemize}
	\item[] F -- ($r \times \frac{r(r+1)}{2}$ array) learned quadratic operator
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] H -- ($r \times r^2$ array) symmetric quadratic operator
\end{itemize}

\end{enumerate}
\newpage
\subsection{\code{integration\_helpers.py}}
Import the integration helper script as\\
 \indent \code{from operator\_inference import integration\_helpers}. \\


\subsubsection{\code{integration\_helpers.py} functions}
\label{sec:integrationhelpersfunctions}
 The following functions are supported and called as \code{integration\_helpers.function\_name()}. 
\begin{enumerate}
\item{\code{rk4advance\_L(x,dt,A,B=0,u=0)}}\\
One step of 4th order runge kutta integration of a system of the form $\dot{\bx} = \bA\bx$

\textbf{Parameters}:
	\begin{itemize}
	\item[] x -- ($r\times 1$ array) current reduced state 
	\item[] dt -- (float) time step size
	\item[] A -- ($r \times r$ array) linear operator
	\item[] B -- ($r \times p$ array, optional default = 0) input operator (only needed if \code{input = True}).
	\item[] u -- ($p \times 1$ array, optional default = 0) the input at the current time step (only needed if \code{input = True}).
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] x -- ($r \times 1$ array) reduced state at the next time step
\end{itemize}

\item{\code{rk4advance\_Lc(x,dt,A,c,B=0,u=0)}}\\
One step of 4th order runge kutta integration of a system of the form $\dot{\bx} = \bA\bx + \bc$

\textbf{Parameters}:
	\begin{itemize}
	\item[] x -- ($r\times 1$ array) current reduced state 
	\item[] dt -- (float) time step size
	\item[] A -- ($r \times r$ array) linear operator
	\item[] c -- ($r \times 1$ array) constant term
	\item[] B -- ($r \times p$ array, optional default = 0) input operator (only needed if \code{input = True}).
	\item[] u -- ($p \times 1$ array, optional default = 0) the input at the current time step (only needed if \code{input = True}).
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] x -- ($r \times 1$ array) reduced state at the next time step
\end{itemize}


\item{\code{rk4advance\_LQ(x,dt,A,H,B=0,u=0)}}\\
One step of 4th order runge kutta integration of a system of the form $\dot{\bx} = \bA\bx + \bH (\bx \otimes \bx)$

\textbf{Parameters}:
	\begin{itemize}
	\item[] x -- ($r\times 1$ array) current reduced state 
	\item[] dt -- (float) time step size
	\item[] A -- ($r \times r$ array) linear operator
	\item[] H -- ($r \times r^2$ array) quadratic operator
	\item[] B -- ($r \times p$ array, optional default = 0) input operator (only needed if \code{input = True}).
	\item[] u -- ($p \times 1$ array, optional default = 0) the input at the current time step (only needed if \code{input = True}).
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] x -- ($r \times 1$ array) reduced state at the next time step
\end{itemize}

\item{\code{rk4advance\_LQc(x,dt,A,H,c,B=0,u=0)}}\\
One step of 4th order runge kutta integration of a system of the form $\dot{\bx} = \bA\bx + \bH (\bx \otimes \bx) + \bc$

\textbf{Parameters}:
	\begin{itemize}
	\item[] x -- ($r\times 1$ array) current reduced state 
	\item[] dt -- (float) time step size
	\item[] A -- ($r \times r$ array) linear operator
	\item[] H -- ($r \times r^2$ array) quadratic operator
	\item[] c -- ($r \times 1$ array) constant term
	\item[] B -- ($r \times p$ array, optional default = 0) input operator (only needed if \code{input = True}).
	\item[] u -- ($p \times 1$ array, optional default = 0) the input at the current time step (only needed if \code{input = True}).
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] x -- ($r \times 1$ array) reduced state at the next time step
\end{itemize}

\item{\code{rk4advance\_Q(x,dt,H,B=0,u=0)}}\\
One step of 4th order runge kutta integration of a system of the form $\dot{\bx} = \bH (\bx \otimes \bx) $

\textbf{Parameters}:
	\begin{itemize}
	\item[] x -- ($r\times 1$ array) current reduced state 
	\item[] dt -- (float) time step size
	\item[] H -- ($r \times r^2$ array) quadratic operator
	\item[] B -- ($r \times p$ array, optional default = 0) input operator (only needed if \code{input = True}).
	\item[] u -- ($p \times 1$ array, optional default = 0) the input at the current time step (only needed if \code{input = True}).
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] x -- ($r \times 1$ array) reduced state at the next time step
\end{itemize}

\item{\code{rk4advance\_Qc(x,dt,H,c,B=0,u=0)}}\\
One step of 4th order runge kutta integration of a system of the form $\dot{\bx} = \bH (\bx \otimes \bx) + \bc$

\textbf{Parameters}:
	\begin{itemize}
	\item[] x -- ($r\times 1$ array) current reduced state 
	\item[] dt -- (float) time step size
	\item[] H -- ($r \times r^2$ array) quadratic operator
	\item[] c -- ($r \times 1$ array) constant term
	\item[] B -- ($r \times p$ array, optional default = 0) input operator (only needed if \code{input = True}).
	\item[] u -- ($p \times 1$ array, optional default = 0) the input at the current time step (only needed if \code{input = True}).
	\end{itemize}
\textbf{Returns}:
\begin{itemize}
\item[] x -- ($r \times 1$ array) reduced state at the next time step
\end{itemize}
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Operator inference on GEMS data}
\hrulefill\\
\textbf{Scripts}: \code{main.py}\\
\textbf{Dependencies}: operator\_inference package

\noindent\hrulefill\\

The script \code{main.py} performs operator inference on the GEMS data, simulates the learned system and plots some results. There are a number of user inputs that must be defined within the script. They are as follows
\begin{description}
	\item[k\_ridge] -- (list of floats) The value or values to use for regularization parameter. If multiple values are given, the script loops, generating results for each value. 

	\item[r\_vals] -- (list of ints) The POD basis size or sizes. If multiple values are given, the script loops, generating results for each value. You must have an SVD dataset and a reduced dataset corresponding to each r\_val. 

	\item[train\_time] -- (int) Number of snapshots for learning the operators.

	\item[forecast\_time] -- (int) Number of time steps to predict. The script will predict train\_time + forecast\_time time steps.

	\item[plot\_svd] -- (bool) True = plot singular value decay. False = don't plot.

	\item[compute\_species\_integral] -- (bool) True = compute sum of each species at each time step and save to file. False = Dont compute sum 

	\item[plot\_forecast] -- (bool) True = plot the time trace of predictions at element\_to\_plot locations in the domain. You can also save these plots by uncommenting the line in the script ($\approx$ line 350 and 351). False = dont plot it or save it. 

	\item[element\_to\_plot] -- (list of ints between 0 and 38523) Which element to plot time trace for.

	\item[output\_filename] -- (string) If you decide to save the time traces, this is the filename to save them to. 

	\item[save\_forecast] -- (bool) True = save data for prediction in text file. False = dont save data

	\item[save\_data] -- (bool) True = save the predicted, full dimensional state vector (p,u,v,T,ch4 molar, o2 molar, co2 molar, h2o molar), and error at time step time\_to\_save. False = dont save. 

	\item[time\_to\_save] -- (int) The time step to save, must be less than train\_time + forecast\_time. Currently can only accept one time step to save at a time. 

	\item[monitor\_unphysical\_values] -- (bool) True = count the negative values at each time step occuring in each full dimensional variable and save to "Unphysical\_Values\_Timestep.txt". False = don't do this. 

	\item[datafilefolder] -- (string) The folder containing the projected data. Files inside folder should be called "data\_reduced\_\%d.h5" \%d is the POD basis size. Should have datasets 'data'. This is the format used by \code{projection\_helpers.py}.

	\item[xdotfilefolder] -- (string) The folder containing the projected xdot. Files inside folder should be called "xdot\_reduced\_\%d.h5" \%d is the POD basis size. Should have dataset 'xdot'. This is the format used by \code{projection\_helpers.py}.

	\item[fulldatapath] -- (string) Full filepath for the full dimensional data, should be in dataset 'data' in an hdf5 file. 

	\item[svd\_filepath] -- (string) Full filepath for the SVD, should be in a data set 'U' and 'S' in an hdf5 file.

\end{description}
\noindent Once these inputs are chosen, simply run the file from the command prompt as \\
\indent \code{python3 main.py}\\

\noindent The code also outputs the timing for the steps of operator inference. 
\newpage
\section{Preparing results for tecplot}
\hrulefill\\
\textbf{Scripts}: \code{csv2tec.py}\\
\textbf{Dependencies}: \code{save\_as\_tec.m}, \code{importGridFile.m}, \code{importTecASCIIdata.m}, \code{OutputTecASCIIdata.m} \code{grid.dat}, matlab package

\noindent\hrulefill\\
If save\_data == True when you run \code{main.py}, then you can plot the resulting field plots in tecplot. You will need TecPlot 360. \\

\noindent Install the matlab package, so we can call the matlab formatting scripts. In the command line type \\
\indent \code{pip install matlab} \\
\noindent You must install this using python2's pip. \\

\noindent In the script \code{csv2tec.py}, there is a main function with some user inputs you must define corresponding to the data you saved. Once thats done, save the csv results files to a tecplot formatted .dat file by typing the command\\
\indent \code{python csv2tec.py}\\
\noindent This must be run using python 2\\

This will produce .dat files with the same name plus an additional ``\_formatted". In TecPlot, go to \\
 File $>>$ Load Data $>>$ Choose the file $>>$ Choose Tecplot Data Loader $>>$ OK.

Once the domain is visible on the screen, View $>>$ Plot Sidebar. On the side bar, select the contour box and click details to choose different variables and colorings. 

%
%\section{Folders}
%\subsection{data}
%The data folder contains hdf5 files of the reduced data and xdot data for use in operator inference.
%\begin{itemize}
%\item[--]  \textbf{data}  
%	\begin{itemize}
%	\item[--] \textbf{data\_reduced\_minmax\_nt2500}
%		\begin{itemize}
%		\item[--]  data\_reduced\_r.h5
%		\item[]  $\vdots$
%		\item[--]  xdot\_reduced\_r.h5
%		\item[]  $\vdots$
%		\end{itemize}
%	\item[--]  \textbf{data\_reduced\_minmax\_nt5000}	
%	\item[--]  \textbf{data\_reduced\_minmax\_nt7500}
%	\item[--]  \textbf{data\_reduced\_minmax\_nt10000}
%	\end{itemize}
%\end{itemize}
%They are read with the following commands\\
%\code{data\_file = h5py.File(`data\_reduced\_r8.h5',`r')}\\
%\code{data = data\_file[`data']} -- $8n_x \times nt$ array\\
%\code{xdot\_file = h5py.File(`xdot\_reduced\_r8.h5',`r')}\\
%\code{xdot = xdot\_file[`xdot']} -- $8n_x \times nt$ array
%
%
%\subsection{svd}
%The svd folder contains the svd of the four training sizes used on the these. 
%\begin{itemize}
%\item[--] \textbf{svd}
%	\begin{itemize}
%	\item[--] svd\_nt2500.h5
%	\item[--] svd\_nt5000.h5
%	\item[--] svd\_nt7500.h5
%	\item[--] svd\_nt10000.h5
%	\end{itemize}
%
%\end{itemize}
%They are each stored in an hdf5 file. The files are read with the following commands \\
%\code{svd\_file = h5py.File(`svd\_nt5000.h5',`r')}\\
%\code{singular\_values = svd\_file[`Snd']}\\
%\code{singular\_vectors = svd\_file[`Und']}
%\subsection{results}
%\begin{itemize}
%\item[--] \textbf{results}
%	\begin{itemize}
%		\item[--] \textbf{integrated species}
%			\begin{itemize}
%			\item[--] true\_integral\_species.txt
%			\item[--] integral\_species\_r17\_nt10000\_l30000.txt
%			\item[] $\vdots$
%			\item[--] integral\_species\_r29\_nt10000\_l30000.txt
%			\end{itemize}
%		\item[--] \textbf{field\_data}
%		\begin{itemize}
%		\item[--] data\_t9999.csv
%		\item[--] xr\_t9999\_r\_nt.csv
%		\item[--] relerror\_t9999\_r\_nt.csv
%		\item[--] abs\_error\_t9999\_r\_nt.csv
%		\item[--]
%		\end{itemize}
%	\end{itemize}
%\item[--]\textbf{timetraces}
%	
%\end{itemize}
%
%\subsection{A subsection}
%
%More text.

\begin{thebibliography}{1}
\bibitem{ben}
 Peherstorfer, Benjamin and Willcox, Karen, Data-driven operator inference for nonintrusive projection-based model reduction, \textit{Computer Methods in Applied Mechanics and Engineering}, volume 306, pages 196--215, 2016

\bibitem{mythesis}
Swischuk, Renee, Physics-based machine learning and data-driven reduced-order modeling, \textit{MIT Master's Thesis}, 2019

\end{thebibliography}
\end{document}
